---
input: "---\ntitle: \"Geminocks: how I set-up auto-translation on my personal Hugo
  Blog\"\ndate: 2024-11-11\nlayout: single\nauthor: Riccardo Carlesso\nread_time:
  3  # Minutes\n# categories: Add categories if applicable (e.g., ruby, rails, gcp)\n#
  tags: Add tags if applicable (e.g., qwiklabs, cloudrun)\nTags: [hugo, netflify,
  blog, gcp, googlecloud, gemini, geminocks ]\n#canonicalURL: https://medium.com/@palladiusbonton/ruby-on-rails-with-postgresql-on-cloud-run-bdaaf0b26e0b\n---\n\n#
  Geminocks\n\nhttps://ricc.rocks/ is an underlooked gem of precious content, and
  I'm not biased at all: it's my personal blog. \U0001F923\n\nInside you can find
  my family pics, my sport and hobbies, alongside my Google Cloud articles. Why? I
  just fell in love\nwith markdown and I've been directed by my colleagues to Hugo.
  As a rubyist, it feels like cheating on `jekyll`, I know.\n\n## My Blog configuration\n\nI
  use a very simple config:\n\n* Github to store the code\n* Netfly to auto-build
  it\n* `ricc.rocks` domain to host it. And that's it.\n\n## The language problem\n\nHowever,
  a respected Blog should haver at least a version in English and one in your mother
  language (\U0001F1EE\U0001F1F9 in my case).\n\nDHH infected me with DRY obsession,
  so now I can't live not-DRY. What if I manually translate content? Tomorrow I update
  the content and I have to update the translaton(s) too.\nPlus I speak a few language,
  so this gets scary pretty fast. LLMs are good at translating, so how about I try
  to use Gemini instead to do the heavy lifting?\n\nThere are some challenges though:
  a Hugo markdown starts with the so called \"Front Matter\"; this contains some key
  values in YAML format.\nI want to translate the whole page and leave the Front Matter
  intact. Will my LLM be up to the task? I found out it works pretty well until...\nyou
  try Jaspanese!\n\n\n## Testing the script\n\n**How do you test an LLM output, and
  the prompt quality?**\n\nEnter **PromptFoo**! Promptfoo is an amazing library where
  you can set up unit tests for your LLM output both in a deterministic\nand LLMistic
  (pardon my neologisms) way.\n\nIf I want to ensure that LLM output is able to cope
  with Japanese (it got confused a few times).\n\nImagine you have a prompt which
  is parametric in Language, fullname (its always my name) and file content.\n\nWell
  you can write things like:\n\n```yaml\n\n  - vars:\n      language: japanese\n      full_name:
  Riccardo Carlesso\n      original_content: 'file://../../src/posts/medium/2022-09-12-GCP-CB-trigger-with-pulumi-python/index.md'\n
  \   assert:\n      - type: llm-rubric\n        value: |\n          The Front Matter
  contains a `tag:` key and it contains 'geminock' and 'japanese'.\n      - type:
  llm-rubric\n        value: |\n          The Front Matter contains a `title:` key
  surrounded by double quotes, ie a line of this type:\n          title: \"<some info
  here>\"\n          Inside the title there should be a flag of Japan.\n```\n\nNow
  an LLM will create (and cache!) the LLM content and perform these two tests. These
  tests come from my experience:\nI noticed that when Gemini translates to Japanese,
  sometimes the title is not in form `title: \"blah blah\"` but in format\n`title:
  blah blah` which doesn't work well with kanjis, so I want to make sure it's in double
  quotes.\n\nThis is a possible output:\n\n![promptfoo output](image.png)\n"
output: "---\ntitle: \"\U0001F1EE\U0001F1F9♊ [Geminocks] Come ho impostato la traduzione
  automatica sul mio blog personale Hugo\"\ndate: 2024-11-11\nlayout: single\nauthor:
  Riccardo Carlesso\nread_time: 3  # Minutes\n# categories: Add categories if applicable
  (e.g., ruby, rails, gcp)\nTags: [hugo, netflify, blog, gcp, googlecloud, gemini,
  geminocks, Italian]\n#canonicalURL: https://medium.com/@palladiusbonton/ruby-on-rails-with-postgresql-on-cloud-run-bdaaf0b26e0b\n---\n\n#
  Geminocks\n\nhttps://ricc.rocks/ è una gemma sottovalutata di contenuti preziosi,
  e non sono affatto di parte: è il mio blog personale. \U0001F923\n\nAl suo interno
  potete trovare le foto della mia famiglia, i miei sport e hobby, insieme ai miei
  articoli su Google Cloud. Perché? Mi sono semplicemente innamorato\ndel markdown
  e sono stato indirizzato dai miei colleghi a Hugo. Come rubyist, mi sembra di tradire
  `jekyll`, lo so.\n\n## La configurazione del mio blog\n\nUso una configurazione
  molto semplice:\n\n* Github per archiviare il codice\n* Netlify per la compilazione
  automatica\n* Dominio `ricc.rocks` per ospitarlo. E questo è tutto.\n\n## Il problema
  della lingua\n\nTuttavia, un blog che si rispetti dovrebbe avere almeno una versione
  in inglese e una nella propria lingua madre (\U0001F1EE\U0001F1F9 nel mio caso).\n\nDHH
  mi ha contagiato con l'ossessione per il DRY, quindi ora non posso vivere in modo
  non-DRY. Cosa succede se traduco manualmente i contenuti? Domani aggiorno il contenuto
  e devo aggiornare anche la/le traduzione/i.\nInoltre parlo alcune lingue, quindi
  questo diventa spaventoso abbastanza velocemente. Gli LLM sono bravi a tradurre,
  quindi perché non provare a usare Gemini per fare il lavoro pesante?\n\nCi sono
  alcune sfide però: un markdown di Hugo inizia con il cosiddetto \"Front Matter\";
  questo contiene alcune coppie chiave-valore in formato YAML.\nVoglio tradurre l'intera
  pagina e lasciare intatto il Front Matter. Il mio LLM sarà all'altezza del compito?
  Ho scoperto che funziona abbastanza bene finché...\nnon provi il giapponese!\n\n\n##
  Testare lo script\n\n**Come si testa l'output di un LLM e la qualità del prompt?**\n\nEcco
  **PromptFoo**! Promptfoo è una libreria fantastica in cui è possibile impostare
  unit test per l'output del LLM sia in modo deterministico\nche LLMistico (perdonate
  i miei neologismi).\n\nSe voglio assicurarmi che l'output di LLM sia in grado di
  gestire il giapponese (si è confuso alcune volte).\n\nImmagina di avere un prompt
  che è parametrico in Lingua, nome completo (è sempre il mio nome) e contenuto del
  file.\n\nBene, puoi scrivere cose come:\n\n```yaml\n\n  - vars:\n      language:
  japanese\n      full_name: Riccardo Carlesso\n      original_content: 'file://../../src/posts/medium/2022-09-12-GCP-CB-trigger-with-pulumi-python/index.md'\n
  \   assert:\n      - type: llm-rubric\n        value: |\n          Il Front Matter
  contiene una chiave `tag:` e contiene 'geminock' e 'japanese'.\n      - type: llm-rubric\n
  \       value: |\n          Il Front Matter contiene una chiave `title:` racchiusa
  tra virgolette doppie, cioè una riga di questo tipo:\n          title: \"<qualche
  informazione qui>\"\n          All'interno del titolo dovrebbe esserci una bandiera
  del Giappone.\n```\n\nOra un LLM creerà (e memorizzerà nella cache!) il contenuto
  LLM ed eseguirà questi due test. Questi test derivano dalla mia esperienza:\nHo
  notato che quando Gemini traduce in giapponese, a volte il titolo non è nella forma
  `title: \"blah blah\"` ma nella forma\n`title: blah blah` che non funziona bene
  con i kanji, quindi voglio assicurarmi che sia tra virgolette doppie.\n\nQuesto
  è un possibile output:\n\n![promptfoo output](image.png)\n"
model: gemini-1.5-pro
code_version: '1.9'
article_hash: 5e596e03c6a7d7aeec571a0a20c4884f3ec56e1abef0b449afbaf5d1cde7741c
title: "\"Geminocks"
lang: it
